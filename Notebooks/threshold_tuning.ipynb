{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a495406",
   "metadata": {},
   "source": [
    "## CELL 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0b3359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from XAI_engine.xai_engine import FakeReviewXAI\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b4b48",
   "metadata": {},
   "source": [
    "## CELL 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70340995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 40,432\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "CG    20216\n",
      "OR    20216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CG = Computer Generated (FAKE)\n",
      "OR = Original (GENUINE)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/fake_reviews_dataset.csv')\n",
    "\n",
    "print(f\"Total reviews: {len(df):,}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nCG = Computer Generated (FAKE)\")\n",
    "print(f\"OR = Original (GENUINE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebcabe",
   "metadata": {},
   "source": [
    "## CELL 3: Prepare Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c75183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: 100 reviews\n",
      "Fake: 50\n",
      "Genuine: 50\n"
     ]
    }
   ],
   "source": [
    "n_samples = 50\n",
    "\n",
    "fake_samples = df[df['label'] == 'CG'].sample(n=n_samples, random_state=42)\n",
    "genuine_samples = df[df['label'] == 'OR'].sample(n=n_samples, random_state=42)\n",
    "\n",
    "validation_df = pd.concat([fake_samples, genuine_samples])\n",
    "validation_df['is_fake'] = validation_df['label'] == 'CG'\n",
    "validation_df = validation_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Validation set: {len(validation_df)} reviews\")\n",
    "print(f\"Fake: {validation_df['is_fake'].sum()}\")\n",
    "print(f\"Genuine: {(~validation_df['is_fake']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca8962",
   "metadata": {},
   "source": [
    "## CELL 4: Tuning Function\n",
    "Purpose: Test XAI engine on reviews and record predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c7bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning function ready\n"
     ]
    }
   ],
   "source": [
    "def tune_thresholds(reviews_df, xai_engine):\n",
    "    \n",
    "    \"\"\"Test XAI engine on labeled data\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in reviews_df.iterrows():\n",
    "        try:\n",
    "            analysis = xai_engine.analyze_review(row['text_'])\n",
    "            \n",
    "            predicted_fake = analysis['verdict'] in ['LIKELY FAKE', 'SUSPICIOUS']\n",
    "            actual_fake = row['is_fake']\n",
    "            \n",
    "            results.append({\n",
    "                'actual_fake': actual_fake,\n",
    "                'predicted_fake': predicted_fake,\n",
    "                'verdict': analysis['verdict'],\n",
    "                'confidence': analysis['confidence'],\n",
    "                'flag_count': analysis['flag_count'],\n",
    "                'correct': predicted_fake == actual_fake\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error on review {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Tuning function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8455e",
   "metadata": {},
   "source": [
    "## CELL 5: Calculate Metrics function\n",
    "Purpose: Compute accuracy, precision, recall, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cf2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics function ready\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(results):\n",
    "    \n",
    "    \"\"\"Calculate performance metrics\"\"\"\n",
    "    \n",
    "    tp = sum(1 for r in results if r['actual_fake'] and r['predicted_fake'])\n",
    "    fp = sum(1 for r in results if not r['actual_fake'] and r['predicted_fake'])\n",
    "    tn = sum(1 for r in results if not r['actual_fake'] and not r['predicted_fake'])\n",
    "    fn = sum(1 for r in results if r['actual_fake'] and not r['predicted_fake'])\n",
    "    \n",
    "    total = len(results)\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn,\n",
    "        'total_samples': total\n",
    "    }\n",
    "\n",
    "print(\"Metrics function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e1bb1",
   "metadata": {},
   "source": [
    "## cell 6 : Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0cef5",
   "metadata": {},
   "source": [
    "### CELL 6A: Stage 1 - Optimize Tier 1 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645d1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage Grid Search for Optimal Thresholds\n",
      "============================================================\n",
      "\n",
      "STAGE 1: Optimizing Tier 1 Features\n",
      "Testing: Sentiment, Word Count, Adj/Noun Ratio, First-Person Ratio\n",
      "\n",
      "Stage 1 combinations: 135\n",
      "  Progress: 20/135 (15%)\n",
      "  Progress: 40/135 (30%)\n",
      "  Progress: 60/135 (44%)\n",
      "  Progress: 80/135 (59%)\n",
      "  Progress: 100/135 (74%)\n",
      "  Progress: 120/135 (89%)\n",
      "\n",
      "Stage 1 Complete!\n",
      "Best Tier 1 Accuracy: 60.00%\n",
      "\n",
      "Optimal Tier 1 Thresholds:\n",
      "  SENTIMENT_EXTREME:    0.95\n",
      "  WORD_COUNT_MIN:       20\n",
      "  ADJ_NOUN_RATIO:       2.0\n",
      "  FIRST_PERSON_RATIO:   0.1\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 6A: Stage 1 - Optimize Tier 1 Features\n",
    "# ========================================\n",
    "from itertools import product\n",
    "\n",
    "print(\"Two-Stage Grid Search for Optimal Thresholds\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSTAGE 1: Optimizing Tier 1 Features\")\n",
    "print(\"Testing: Sentiment, Word Count, Adj/Noun Ratio, First-Person Ratio\\n\")\n",
    "\n",
    "# Define Tier 1 ranges\n",
    "sentiment_range = [0.75, 0.80, 0.85, 0.90, 0.95]\n",
    "word_min_range = [10, 15, 20]\n",
    "adj_noun_range = [2.0, 2.5, 3.0]\n",
    "first_person_range = [0.10, 0.15, 0.20]\n",
    "\n",
    "total_stage1 = len(sentiment_range) * len(word_min_range) * len(adj_noun_range) * len(first_person_range)\n",
    "print(f\"Stage 1 combinations: {total_stage1}\")\n",
    "\n",
    "stage1_results = []\n",
    "counter = 0\n",
    "\n",
    "for sent, word_min, adj_noun, first_p in product(\n",
    "    sentiment_range, word_min_range, adj_noun_range, first_person_range\n",
    "):\n",
    "    counter += 1\n",
    "    \n",
    "    if counter % 20 == 0: #Print progress every 20 iterations\n",
    "        print(f\"  Progress: {counter}/{total_stage1} ({counter/total_stage1:.0%})\")\n",
    "    \n",
    "    # Create config with FIXED Tier 2 values\n",
    "    config = {\n",
    "        'name': f'Stage1_{counter}',\n",
    "        'SENTIMENT_EXTREME': sent,\n",
    "        'WORD_COUNT_MIN': word_min,\n",
    "        'WORD_COUNT_MAX': 200,\n",
    "        'ADJ_NOUN_RATIO': adj_noun,\n",
    "        'FIRST_PERSON_RATIO': first_p,\n",
    "        'SPAM_KEYWORD_MIN': 3,\n",
    "        'CAPS_RATIO_MAX': 0.20,\n",
    "        'EXCESSIVE_PUNCT_MIN': 3,\n",
    "        'UNIQUENESS_RATIO_MIN': 0.60\n",
    "    }\n",
    "    \n",
    "    # Test configuration\n",
    "    xai = FakeReviewXAI()\n",
    "    config_thresholds = {k: v for k, v in config.items() if k != 'name'} #creates threshold dictionary without 'name' to update object thresholds\n",
    "    xai.thresholds.update(config_thresholds)\n",
    "    \n",
    "    results = tune_thresholds(validation_df, xai)\n",
    "    metrics = calculate_metrics(results)\n",
    "    \n",
    "    config_result = config.copy()\n",
    "    config_result.update(metrics)\n",
    "    stage1_results.append(config_result)\n",
    "\n",
    "# Get best Tier 1 configuration\n",
    "stage1_df = pd.DataFrame(stage1_results)\n",
    "stage1_df = stage1_df.sort_values('accuracy', ascending=False, ignore_index=True)\n",
    "best_tier1 = stage1_df.iloc[0]\n",
    "\n",
    "print(f\"\\nStage 1 Complete!\")\n",
    "print(f\"Best Tier 1 Accuracy: {best_tier1['accuracy']:.2%}\")\n",
    "print(f\"\\nOptimal Tier 1 Thresholds:\")\n",
    "print(f\"  SENTIMENT_EXTREME:    {best_tier1['SENTIMENT_EXTREME']}\")\n",
    "print(f\"  WORD_COUNT_MIN:       {best_tier1['WORD_COUNT_MIN']}\")\n",
    "print(f\"  ADJ_NOUN_RATIO:       {best_tier1['ADJ_NOUN_RATIO']}\")\n",
    "print(f\"  FIRST_PERSON_RATIO:   {best_tier1['FIRST_PERSON_RATIO']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8506eb50",
   "metadata": {},
   "source": [
    "### CELL 6B: Stage 2 - Optimize Tier 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b87f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STAGE 2: Optimizing Tier 2 Features\n",
      "Testing: Spam Keywords, Caps, Punctuation, Redundancy\n",
      "\n",
      "Stage 2 combinations: 81\n",
      "  Progress: 15/81 (19%)\n",
      "  Progress: 30/81 (37%)\n",
      "  Progress: 45/81 (56%)\n",
      "  Progress: 60/81 (74%)\n",
      "  Progress: 75/81 (93%)\n",
      "\n",
      "Stage 2 Complete!\n",
      "Best Overall Accuracy: 60.00%\n",
      "\n",
      "Optimal Tier 2 Thresholds:\n",
      "  SPAM_KEYWORD_MIN:     4\n",
      "  CAPS_RATIO_MAX:       0.25\n",
      "  EXCESSIVE_PUNCT_MIN:  3\n",
      "  UNIQUENESS_RATIO_MIN: 0.6\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 6B: Stage 2 - Optimize Tier 2 Features\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAGE 2: Optimizing Tier 2 Features\")\n",
    "print(\"Testing: Spam Keywords, Caps, Punctuation, Redundancy\\n\")\n",
    "\n",
    "# Define Tier 2 ranges\n",
    "spam_keyword_range = [2, 3, 4]\n",
    "caps_ratio_range = [0.15, 0.20, 0.25]\n",
    "punct_range = [2, 3, 4]\n",
    "uniqueness_range = [0.55, 0.60, 0.65]\n",
    "\n",
    "total_stage2 = len(spam_keyword_range) * len(caps_ratio_range) * len(punct_range) * len(uniqueness_range)\n",
    "print(f\"Stage 2 combinations: {total_stage2}\")\n",
    "\n",
    "stage2_results = []\n",
    "counter = 0\n",
    "\n",
    "for spam, caps, punct, unique in product(\n",
    "    spam_keyword_range, caps_ratio_range, punct_range, uniqueness_range\n",
    "):\n",
    "    counter += 1\n",
    "    \n",
    "    if counter % 15 == 0:\n",
    "        print(f\"  Progress: {counter}/{total_stage2} ({counter/total_stage2:.0%})\")\n",
    "    \n",
    "    # Create config with OPTIMAL Tier 1 + varying Tier 2\n",
    "    config = {\n",
    "        'name': f'Stage2_{counter}',\n",
    "        # Tier 1 - FIXED at optimal from Stage 1\n",
    "        'SENTIMENT_EXTREME': best_tier1['SENTIMENT_EXTREME'],\n",
    "        'WORD_COUNT_MIN': best_tier1['WORD_COUNT_MIN'],\n",
    "        'WORD_COUNT_MAX': 200,\n",
    "        'ADJ_NOUN_RATIO': best_tier1['ADJ_NOUN_RATIO'],\n",
    "        'FIRST_PERSON_RATIO': best_tier1['FIRST_PERSON_RATIO'],\n",
    "        # Tier 2 - SEARCHING\n",
    "        'SPAM_KEYWORD_MIN': spam,\n",
    "        'CAPS_RATIO_MAX': caps,\n",
    "        'EXCESSIVE_PUNCT_MIN': punct,\n",
    "        'UNIQUENESS_RATIO_MIN': unique\n",
    "    }\n",
    "    \n",
    "    # Test configuration\n",
    "    xai = FakeReviewXAI()\n",
    "    config_thresholds = {k: v for k, v in config.items() if k != 'name'}\n",
    "    xai.thresholds.update(config_thresholds)\n",
    "    \n",
    "    results = tune_thresholds(validation_df, xai)\n",
    "    metrics = calculate_metrics(results)\n",
    "    \n",
    "    config_result = config.copy()\n",
    "    config_result.update(metrics)\n",
    "    stage2_results.append(config_result)\n",
    "\n",
    "# Get best overall configuration\n",
    "stage2_df = pd.DataFrame(stage2_results)\n",
    "stage2_df = stage2_df.sort_values('accuracy', ascending=False, ignore_index=True)\n",
    "best_overall = stage2_df.iloc[0]\n",
    "\n",
    "print(f\"\\nStage 2 Complete!\")\n",
    "print(f\"Best Overall Accuracy: {best_overall['accuracy']:.2%}\")\n",
    "print(f\"\\nOptimal Tier 2 Thresholds:\")\n",
    "print(f\"  SPAM_KEYWORD_MIN:     {best_overall['SPAM_KEYWORD_MIN']}\")\n",
    "print(f\"  CAPS_RATIO_MAX:       {best_overall['CAPS_RATIO_MAX']}\")\n",
    "print(f\"  EXCESSIVE_PUNCT_MIN:  {best_overall['EXCESSIVE_PUNCT_MIN']}\")\n",
    "print(f\"  UNIQUENESS_RATIO_MIN: {best_overall['UNIQUENESS_RATIO_MIN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f48711",
   "metadata": {},
   "source": [
    "### CELL 6C: Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c152a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TWO-STAGE GRID SEARCH COMPLETE!\n",
      "============================================================\n",
      "Total configurations tested: 216\n",
      "Best accuracy achieved: 60.00%\n",
      "\n",
      "Top 10 configurations:\n",
      "     SENTIMENT_EXTREME  WORD_COUNT_MIN  ADJ_NOUN_RATIO  FIRST_PERSON_RATIO  \\\n",
      "0                 0.95              20             2.0                 0.1   \n",
      "142               0.95              20             2.0                 0.1   \n",
      "141               0.95              20             2.0                 0.1   \n",
      "140               0.95              20             2.0                 0.1   \n",
      "139               0.95              20             2.0                 0.1   \n",
      "138               0.95              20             2.0                 0.1   \n",
      "152               0.95              20             2.0                 0.1   \n",
      "135               0.95              20             2.0                 0.1   \n",
      "151               0.95              20             2.0                 0.1   \n",
      "150               0.95              20             2.0                 0.1   \n",
      "\n",
      "     SPAM_KEYWORD_MIN  CAPS_RATIO_MAX  accuracy  f1_score  \n",
      "0                   3            0.20       0.6  0.487179  \n",
      "142                 4            0.20       0.6  0.487179  \n",
      "141                 4            0.20       0.6  0.487179  \n",
      "140                 4            0.15       0.6  0.487179  \n",
      "139                 4            0.15       0.6  0.487179  \n",
      "138                 4            0.15       0.6  0.487179  \n",
      "152                 4            0.25       0.6  0.487179  \n",
      "135                 4            0.25       0.6  0.487179  \n",
      "151                 3            0.15       0.6  0.487179  \n",
      "150                 3            0.15       0.6  0.487179  \n",
      "\n",
      "Full results saved to: data/grid_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 6C: Combine and Save All Results\n",
    "# ========================================\n",
    "# Combine all results\n",
    "all_results = pd.concat([stage1_df, stage2_df], ignore_index=True)\n",
    "all_results = all_results.sort_values('accuracy', ascending=False)\n",
    "all_results.to_csv('../data/grid_search_results.csv', index=False)\n",
    "\n",
    "# Save as grid_df for later cells\n",
    "grid_df = all_results\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TWO-STAGE GRID SEARCH COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total configurations tested: {total_stage1 + total_stage2}\")\n",
    "print(f\"Best accuracy achieved: {best_overall['accuracy']:.2%}\\n\")\n",
    "print(\"Top 10 configurations:\")\n",
    "print(grid_df[['SENTIMENT_EXTREME', 'WORD_COUNT_MIN', 'ADJ_NOUN_RATIO', \n",
    "               'FIRST_PERSON_RATIO', 'SPAM_KEYWORD_MIN', 'CAPS_RATIO_MAX',\n",
    "               'accuracy', 'f1_score']].head(10))\n",
    "\n",
    "print(\"\\nFull results saved to: data/grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebfb59",
   "metadata": {},
   "source": [
    "## CELL 7: Save Top 5 to threshold_tuning.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4dc282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 saved to: data/threshold_tuning.csv\n",
      "\n",
      "Top 5 Results:\n",
      "           name  accuracy  precision  recall  f1_score\n",
      "0    Stage1_127       0.6   0.678571    0.38  0.487179\n",
      "142   Stage2_71       0.6   0.678571    0.38  0.487179\n",
      "141   Stage2_65       0.6   0.678571    0.38  0.487179\n",
      "140   Stage2_62       0.6   0.678571    0.38  0.487179\n",
      "139   Stage2_59       0.6   0.678571    0.38  0.487179\n"
     ]
    }
   ],
   "source": [
    "top_5 = grid_df.head(5)\n",
    "\n",
    "column_order = [\n",
    "    'name', 'SENTIMENT_EXTREME', 'WORD_COUNT_MIN', 'WORD_COUNT_MAX',\n",
    "    'ADJ_NOUN_RATIO', 'FIRST_PERSON_RATIO', 'SPAM_KEYWORD_MIN',\n",
    "    'CAPS_RATIO_MAX', 'EXCESSIVE_PUNCT_MIN', 'UNIQUENESS_RATIO_MIN',\n",
    "    'accuracy', 'precision', 'recall', 'f1_score',\n",
    "    'true_positives', 'false_positives', 'true_negatives', 'false_negatives',\n",
    "    'total_samples'\n",
    "]\n",
    "\n",
    "top_5 = top_5[column_order]\n",
    "top_5.to_csv('../data/threshold_tuning.csv', index=False)\n",
    "\n",
    "print(\"Top 5 saved to: data/threshold_tuning.csv\")\n",
    "print(\"\\nTop 5 Results:\")\n",
    "print(top_5[['name', 'accuracy', 'precision', 'recall', 'f1_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56833e",
   "metadata": {},
   "source": [
    "## CELL 8: Display Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d71fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OPTIMAL CONFIGURATION (Found by Grid Search)\n",
      "============================================================\n",
      "\n",
      "Performance:\n",
      "  Accuracy:  60.00%\n",
      "  Precision: 67.86%\n",
      "  Recall:    38.00%\n",
      "  F1 Score:  48.72%\n",
      "\n",
      "Thresholds:\n",
      "  SENTIMENT_EXTREME:      0.95\n",
      "  WORD_COUNT_MIN:         20\n",
      "  WORD_COUNT_MAX:         200\n",
      "  ADJ_NOUN_RATIO:         2.0\n",
      "  FIRST_PERSON_RATIO:     0.1\n",
      "  SPAM_KEYWORD_MIN:       3\n",
      "  CAPS_RATIO_MAX:         0.2\n",
      "  EXCESSIVE_PUNCT_MIN:    3\n",
      "  UNIQUENESS_RATIO_MIN:   0.6\n"
     ]
    }
   ],
   "source": [
    "best_idx = grid_df['accuracy'].idxmax()\n",
    "best_config = grid_df.iloc[best_idx]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OPTIMAL CONFIGURATION (Found by Grid Search)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Accuracy:  {best_config['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {best_config['precision']:.2%}\")\n",
    "print(f\"  Recall:    {best_config['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {best_config['f1_score']:.2%}\")\n",
    "print(f\"\\nThresholds:\")\n",
    "print(f\"  SENTIMENT_EXTREME:      {best_config['SENTIMENT_EXTREME']}\")\n",
    "print(f\"  WORD_COUNT_MIN:         {best_config['WORD_COUNT_MIN']}\")\n",
    "print(f\"  WORD_COUNT_MAX:         {best_config['WORD_COUNT_MAX']}\")\n",
    "print(f\"  ADJ_NOUN_RATIO:         {best_config['ADJ_NOUN_RATIO']}\")\n",
    "print(f\"  FIRST_PERSON_RATIO:     {best_config['FIRST_PERSON_RATIO']}\")\n",
    "print(f\"  SPAM_KEYWORD_MIN:       {best_config['SPAM_KEYWORD_MIN']}\")\n",
    "print(f\"  CAPS_RATIO_MAX:         {best_config['CAPS_RATIO_MAX']}\")\n",
    "print(f\"  EXCESSIVE_PUNCT_MIN:    {best_config['EXCESSIVE_PUNCT_MIN']}\")\n",
    "print(f\"  UNIQUENESS_RATIO_MIN:   {best_config['UNIQUENESS_RATIO_MIN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3e15b",
   "metadata": {},
   "source": [
    "## CELL 11: Generate config.py Code\n",
    "updates config.py with optimal thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2971eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ config.py successfully updated!\n",
      "\n",
      "File location: c:\\Users\\Amr\\Documents\\GitHub\\Team-C-repository\\xai_engine\\config.py\n",
      "\n",
      "============================================================\n",
      "üèÜ OPTIMAL CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "Performance:\n",
      "  Accuracy:  60.00%\n",
      "  Precision: 67.86%\n",
      "  Recall:    38.00%\n",
      "  F1 Score:  48.72%\n",
      "\n",
      "Optimal Thresholds (now in config.py):\n",
      "  SENTIMENT_EXTREME:      0.95\n",
      "  WORD_COUNT_MIN:         20\n",
      "  WORD_COUNT_MAX:         200\n",
      "  ADJ_NOUN_RATIO:         2.0\n",
      "  FIRST_PERSON_RATIO:     0.1\n",
      "  SPAM_KEYWORD_MIN:       3\n",
      "  CAPS_RATIO_MAX:         0.2\n",
      "  EXCESSIVE_PUNCT_MIN:    3\n",
      "  UNIQUENESS_RATIO_MIN:   0.6\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 11: Auto-Update config.py\n",
    "# ========================================\n",
    "import os\n",
    "\n",
    "\n",
    "# Generate the new config content\n",
    "new_config_content = f'''\"\"\"\n",
    "XAI Engine Configuration\n",
    "Centralized thresholds for all features (Tier 1 + Tier 2)\n",
    "Auto-generated by threshold_tuning.ipynb\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# ALL THRESHOLDS (TIER 1 + TIER 2) - OPTIMIZED\n",
    "# ============================================================================\n",
    "\n",
    "THRESHOLDS = {{\n",
    "    # TIER 1: Essential Features\n",
    "    'SENTIMENT_EXTREME': {best_config['SENTIMENT_EXTREME']},\n",
    "    'WORD_COUNT_MIN': {int(best_config['WORD_COUNT_MIN'])},\n",
    "    'WORD_COUNT_MAX': {int(best_config['WORD_COUNT_MAX'])},\n",
    "    'ADJ_NOUN_RATIO': {best_config['ADJ_NOUN_RATIO']},\n",
    "    'FIRST_PERSON_RATIO': {best_config['FIRST_PERSON_RATIO']},\n",
    "    \n",
    "    # TIER 2: Important Features\n",
    "    'SPAM_KEYWORD_MIN': {int(best_config['SPAM_KEYWORD_MIN'])},\n",
    "    'CAPS_RATIO_MAX': {best_config['CAPS_RATIO_MAX']},\n",
    "    'EXCESSIVE_PUNCT_MIN': {int(best_config['EXCESSIVE_PUNCT_MIN'])},\n",
    "    'UNIQUENESS_RATIO_MIN': {best_config['UNIQUENESS_RATIO_MIN']}\n",
    "}}\n",
    "\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Return a copy of thresholds\"\"\"\n",
    "    return THRESHOLDS.copy()\n",
    "\n",
    "\n",
    "def update_thresholds(new_thresholds):\n",
    "    \"\"\"Update thresholds (used by threshold tuning)\"\"\"\n",
    "    THRESHOLDS.update(new_thresholds)\n",
    "'''\n",
    "\n",
    "# Write to config.py\n",
    "config_path = '../xai_engine/config.py'\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(new_config_content)\n",
    "    \n",
    "    print(\"‚úÖ config.py successfully updated!\")\n",
    "    print(f\"\\nFile location: {os.path.abspath(config_path)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error updating config.py: {e}\")\n",
    "    print(\"\\nManual update required. Copy this code:\\n\")\n",
    "    print(new_config_content)\n",
    "\n",
    "# Display the optimal configuration\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ OPTIMAL CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Accuracy:  {best_config['accuracy']:.2%}\")\n",
    "print(f\"  Precision: {best_config['precision']:.2%}\")\n",
    "print(f\"  Recall:    {best_config['recall']:.2%}\")\n",
    "print(f\"  F1 Score:  {best_config['f1_score']:.2%}\")\n",
    "\n",
    "print(f\"\\nOptimal Thresholds (now in config.py):\")\n",
    "print(f\"  SENTIMENT_EXTREME:      {best_config['SENTIMENT_EXTREME']}\")\n",
    "print(f\"  WORD_COUNT_MIN:         {int(best_config['WORD_COUNT_MIN'])}\")\n",
    "print(f\"  WORD_COUNT_MAX:         {int(best_config['WORD_COUNT_MAX'])}\")\n",
    "print(f\"  ADJ_NOUN_RATIO:         {best_config['ADJ_NOUN_RATIO']}\")\n",
    "print(f\"  FIRST_PERSON_RATIO:     {best_config['FIRST_PERSON_RATIO']}\")\n",
    "print(f\"  SPAM_KEYWORD_MIN:       {int(best_config['SPAM_KEYWORD_MIN'])}\")\n",
    "print(f\"  CAPS_RATIO_MAX:         {best_config['CAPS_RATIO_MAX']}\")\n",
    "print(f\"  EXCESSIVE_PUNCT_MIN:    {int(best_config['EXCESSIVE_PUNCT_MIN'])}\")\n",
    "print(f\"  UNIQUENESS_RATIO_MIN:   {best_config['UNIQUENESS_RATIO_MIN']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
